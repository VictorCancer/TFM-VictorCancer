{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parametros de entrada"
      ],
      "metadata": {
        "id": "pwkQ_V2gR80q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los siguientes parametros deben ser modificados seg√∫n como tenga el usuario almacenados los pesos de su modelo as√≠ como la carpeta donde se encuetran los nuevos datos:"
      ],
      "metadata": {
        "id": "SQ9DW7vYTQc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre del nuevo dataset\n",
        "dataset = 'Nuevo-Dataset'\n",
        "\n",
        "# Carpeta donde se encuentran los datos\n",
        "source_folder = '/content/drive/MyDrive/DELT/Nuevo-Dataset'\n",
        "\n",
        "# Carpeta donde se encuentran las im√°genes antiguas\n",
        "old_dataset_path = '/content/drive/MyDrive/DELT/Antiguo-Dataset'\n",
        "\n",
        "# Carpeta donde queremos guardar los resultados\n",
        "project_folder = '/content/drive/MyDrive/DELT/weights'\n",
        "\n",
        "# Modelo del que partimos y carpeta donde lo tenemos guardado\n",
        "model_v = 'Modelo-Anterior'\n",
        "YOLO_model_w = '/content/drive/MyDrive/DELT/weights/'+model_v+'/weights/best.pt'"
      ],
      "metadata": {
        "id": "CZ1MvWqRR_YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el notebook se usan dos ficheros con la configuraci√≥n del modelo (DELT.yaml) y la API key de Comet (.comet.config). Estos ficheros los guardamos en la siguiente ruta:"
      ],
      "metadata": {
        "id": "lKZFnyHTadwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_folder = '/content/drive/MyDrive/DELT'"
      ],
      "metadata": {
        "id": "Qy2rc13CbUJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "lwAGj3GWR2Nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B56AKqz1RxR1"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerias necesarias\n",
        "import shutil\n",
        "from PIL import Image, ImageDraw\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el directorio dataset\n",
        "!mkdir datasets"
      ],
      "metadata": {
        "id": "eJbpPEilSIwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta funci√≥n nos dar√° la lista de ficheros a mover desde Drive\n",
        "def full_name_func(source_folder,dataset,file_exclusion_patterns = [],subdirectories_included = [],frames = 1):\n",
        "\n",
        "    full_name_list = []\n",
        "\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        for directory in dirs:\n",
        "            if directory == 'images':\n",
        "                source_images_path = os.path.join(root, directory)\n",
        "                for file in os.listdir(source_images_path):\n",
        "                    if not file.startswith(tuple(file_exclusion_patterns)):\n",
        "                        src_file = os.path.join(source_images_path, file)\n",
        "                        subfolder = os.path.basename(Path(src_file).parents[1])\n",
        "                        if ((subfolder in subdirectories_included) or (not subdirectories_included)):\n",
        "                            full_name = dataset + '-' + subfolder +'-'+ file\n",
        "                            full_name_list.append(full_name[:-4])\n",
        "\n",
        "    full_name_list.sort()\n",
        "\n",
        "    final_list = [file for i,file in enumerate(full_name_list) if i%frames == 0]\n",
        "\n",
        "    return final_list"
      ],
      "metadata": {
        "id": "CTzcG-R1SJIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movemos la lista de ficheros de Drive a Colab\n",
        "def drive_to_colab(source_folder,destination_images,destination_labels,dataset,file_list):\n",
        "\n",
        "    os.makedirs(destination_images, exist_ok=True)\n",
        "    os.makedirs(destination_labels, exist_ok=True)\n",
        "\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        for directory in dirs:\n",
        "            if directory == 'images':\n",
        "                source_images_path = os.path.join(root, directory)\n",
        "                for file in os.listdir(source_images_path):\n",
        "                    src_file = os.path.join(source_images_path, file)\n",
        "                    dst_file = os.path.join(destination_images, file)\n",
        "\n",
        "                    subfolder = os.path.basename(Path(src_file).parents[1])\n",
        "                    full_name = dataset + '-' + subfolder +'-'+ file\n",
        "                    new_path = os.path.join(destination_images, full_name)\n",
        "\n",
        "                    if full_name[:-4] in file_list:\n",
        "                        shutil.copy(src_file, dst_file)\n",
        "                        shutil.move(dst_file, new_path)\n",
        "            elif directory == 'labels':\n",
        "                source_labels_path = os.path.join(root, directory)\n",
        "                for file in os.listdir(source_labels_path):\n",
        "                    src_file = os.path.join(source_labels_path, file)\n",
        "                    dst_file = os.path.join(destination_labels, file)\n",
        "\n",
        "                    subfolder = os.path.basename(Path(src_file).parents[1])\n",
        "                    full_name = dataset + '-' + subfolder +'-'+ file\n",
        "                    new_path = os.path.join(destination_labels, full_name)\n",
        "\n",
        "                    if full_name[:-4] in file_list:\n",
        "                        shutil.copy(src_file, dst_file)\n",
        "                        shutil.move(dst_file, new_path)"
      ],
      "metadata": {
        "id": "JBLNTLRaaPIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_images = '/content/datasets/DELT/images'\n",
        "destination_labels = '/content/datasets/DELT/labels'\n",
        "\n",
        "file_list = full_name_func(source_folder,dataset)\n",
        "drive_to_colab(source_folder,destination_images,destination_labels,dataset,file_list)"
      ],
      "metadata": {
        "id": "Odzi3jcuTsjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos YOLOv5\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt comet_ml\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "\n",
        "display = utils.notebook_init()"
      ],
      "metadata": {
        "id": "8Hx09_JAQdbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c28ba66-30ae-4e3d-d8c1-7ddf19358797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-388-g882c35fc Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 34.5/235.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Traemos los ficheros de configuraci√≥n de Drive\n",
        "\n",
        "!cp {config_folder}/DELT.yaml data\n",
        "!cp {config_folder}/DELT_validation.yaml data\n",
        "!cp {config_folder}/.comet.config ."
      ],
      "metadata": {
        "id": "zeSGbCcyQd8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la estructura de train/val/test\n",
        "\n",
        "def split_dataset(image_names, train_size, val_size):\n",
        "    for i, image_name in enumerate(image_names):\n",
        "\n",
        "        label_name = image_name.replace('.JPG', '.txt')\n",
        "        label_name = label_name.replace('.jpg', '.txt')\n",
        "\n",
        "        if i < train_size:\n",
        "            split = 'train'\n",
        "        elif i < train_size + val_size:\n",
        "            split = 'val'\n",
        "        else:\n",
        "            split = 'test'\n",
        "\n",
        "        source_image_path = f'../datasets/DELT/images/{image_name}'\n",
        "        source_label_path = f'../datasets/DELT/labels/{label_name}'\n",
        "\n",
        "        target_image_folder = f'../datasets/DELT/images/{split}'\n",
        "        target_label_folder = f'../datasets/DELT/labels/{split}'\n",
        "\n",
        "        shutil.copy(source_image_path, target_image_folder)\n",
        "        try:\n",
        "          shutil.copy(source_label_path, target_label_folder) # No todas las imagenes tienen label\n",
        "        except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "def get_filenames(folder):\n",
        "    filenames = set()\n",
        "\n",
        "    for path in glob.glob(os.path.join(folder, '*.*')):\n",
        "\n",
        "        filename = os.path.split(path)[-1]\n",
        "        filenames.add(filename)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "\n",
        "if not os.path.exists('DELT'):\n",
        "    for folder in ['images', 'labels']:\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            os.makedirs(f'../datasets/DELT/{folder}/{split}')\n",
        "\n",
        "\n",
        "turtle_images = get_filenames('../datasets/DELT/images')\n",
        "turtle_images = np.array(list(turtle_images))\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(turtle_images)\n",
        "\n",
        "train_size = int(np.floor(len(turtle_images)*0.8))\n",
        "val_size = int(np.floor(len(turtle_images)*0.1))\n",
        "\n",
        "split_dataset(turtle_images, train_size, val_size)"
      ],
      "metadata": {
        "id": "V1zJmnY9QhQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metemos en el set de validaci√≥n los datos antiguos en la misma proporcion\n",
        "\n",
        "file_list = full_name_func(old_dataset_path,dataset,frames = n_frames)\n",
        "\n",
        "turtle_images = np.array(list(file_list))\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(turtle_images)\n",
        "\n",
        "\n",
        "# Movemos imagenes al dataset de validaci√≥n\n",
        "destination_images = '/content/datasets/DELT/images/val'\n",
        "destination_labels = '/content/datasets/DELT/labels/val'\n",
        "val_images = turtle_images[:val_size]\n",
        "drive_to_colab(old_dataset_path,destination_images,destination_labels,dataset,val_images)\n",
        "\n",
        "# Movemos imagenes al dataset de test\n",
        "destination_images = '/content/datasets/DELT/images/test'\n",
        "destination_labels = '/content/datasets/DELT/labels/test'\n",
        "test_images = turtle_images[val_size:2*val_size]\n",
        "drive_to_colab(old_dataset_path,destination_images,destination_labels,dataset,test_images)\n"
      ],
      "metadata": {
        "id": "Dls9LTYiTg3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "Yik_ArCGSkTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 üöÄ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY8-ggjRUaxe",
        "outputId": "b1091f2f-6104-4ba7-b0d8-4494c40c0b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_string = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "project_name = dataset + '-' + date_string + '-' + YOLO_model\n",
        "\n",
        "!env COMET_LOG_PER_CLASS_METRICS=true python train.py --data data/DELT.yaml --weights {YOLO_model_w} --epochs 300 --freeze 10 --bbox_interval 1 --patience 15 --project {project_folder} --name {project_name}"
      ],
      "metadata": {
        "id": "DorEO2sgSqLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "ATwlkDkQxoPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testeamos el nuevo modelo contra el dataset de test\n",
        "weigths_path = project_folder + project_name + '/weights/best.pt'\n",
        "project_name = project_name + '-val'\n",
        "\n",
        "# Usamos un .yaml diferente para validar contra la carpeta de test\n",
        "!env COMET_LOG_PER_CLASS_METRICS=true python val.py --data data/DELT_validation.yaml --weights {weigths_path} --project {project_folder} --name {project_name}"
      ],
      "metadata": {
        "id": "GNZcctU31NlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testeamos el antiguo modelo contra el dataset de test\n",
        "weigths_path = project_folder + model_v + '/weights/best.pt'\n",
        "project_name = model_v + '-val'\n",
        "\n",
        "!env COMET_LOG_PER_CLASS_METRICS=true python val.py --data data/DELT_validation.yaml --weights {weigths_path} --project {project_folder} --name {project_name}"
      ],
      "metadata": {
        "id": "SfKQB1kaxmoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}