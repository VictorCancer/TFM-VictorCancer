{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parametros de entrada"
      ],
      "metadata": {
        "id": "pwkQ_V2gR80q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los siguientes parametros deben ser modificados según como tenga el usuario almacenados los pesos de su modelo así como la carpeta donde se encuetran los nuevos datos:"
      ],
      "metadata": {
        "id": "SQ9DW7vYTQc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre del nuevo dataset\n",
        "dataset = 'Nuevo-Dataset'\n",
        "\n",
        "# Carpeta donde se encuentran los datos\n",
        "source_folder = '/content/drive/MyDrive/DELT/Nuevo-Dataset'\n",
        "\n",
        "# Carpeta donde se encuentran las imágenes antiguas\n",
        "old_dataset_path = '/content/drive/MyDrive/DELT/Antiguo-Dataset'\n",
        "\n",
        "# Carpeta donde queremos guardar los resultados\n",
        "project_folder = '/content/drive/MyDrive/DELT/weights'\n",
        "\n",
        "# Modelo del que partimos y carpeta donde lo tenemos guardado\n",
        "model_v = 'Modelo-Anterior'\n",
        "YOLO_model_w = '/content/drive/MyDrive/DELT/weights/'+model_v+'/weights/best.pt'\n"
      ],
      "metadata": {
        "id": "CZ1MvWqRR_YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el notebook se usan dos ficheros con la configuración del modelo (DELTv11.yaml) y la API key de Comet (.comet.config). Estos ficheros los guardamos en la siguiente ruta:"
      ],
      "metadata": {
        "id": "lKZFnyHTadwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_folder = '/content/drive/MyDrive/DELT'"
      ],
      "metadata": {
        "id": "Qy2rc13CbUJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "WmZm3YBzW0aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se adjunta esta libreria porque ultralytics puede dar errores\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# Importamos librerias\n",
        "import shutil\n",
        "from PIL import Image, ImageDraw\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "IDirQR1RUZkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos la librería de ultralytics que contiene YOLOv11\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "lEQAoLj8Y4E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos directorio de datasets y importamos ficheros de configuracion\n",
        "!mkdir datasets\n",
        "\n",
        "!cp {config_folder}/DELTv11.yaml .\n",
        "!cp {config_folder}/DELTv11_validation.yaml .\n",
        "!cp {config_folder}/.comet.config ."
      ],
      "metadata": {
        "id": "TjLld2KYPjH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "582IH6VwYvJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta función nos dará la lista de ficheros a mover desde Drive\n",
        "def full_name_func(source_folder,dataset,file_exclusion_patterns = [],subdirectories_included = [],frames = 1):\n",
        "\n",
        "    full_name_list = []\n",
        "\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        for directory in dirs:\n",
        "            if directory == 'images':\n",
        "                source_images_path = os.path.join(root, directory)\n",
        "                for file in os.listdir(source_images_path):\n",
        "                    if not file.startswith(tuple(file_exclusion_patterns)):\n",
        "                        src_file = os.path.join(source_images_path, file)\n",
        "                        subfolder = os.path.basename(Path(src_file).parents[1])\n",
        "                        if ((subfolder in subdirectories_included) or (not subdirectories_included)):\n",
        "                            full_name = dataset + '-' + subfolder +'-'+ file\n",
        "                            full_name_list.append(full_name[:-4])\n",
        "\n",
        "    full_name_list.sort()\n",
        "\n",
        "    final_list = [file for i,file in enumerate(full_name_list) if i%frames == 0]\n",
        "\n",
        "    return final_list"
      ],
      "metadata": {
        "id": "-Nt2UlW3Xlg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movemos la lista de ficheros de Drive a Colab\n",
        "def drive_to_colab(source_folder,destination_images,destination_labels,dataset,file_list):\n",
        "\n",
        "    os.makedirs(destination_images, exist_ok=True)\n",
        "    os.makedirs(destination_labels, exist_ok=True)\n",
        "\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        for directory in dirs:\n",
        "            if directory == 'images':\n",
        "                source_images_path = os.path.join(root, directory)\n",
        "                for file in os.listdir(source_images_path):\n",
        "                    src_file = os.path.join(source_images_path, file)\n",
        "                    dst_file = os.path.join(destination_images, file)\n",
        "\n",
        "                    subfolder = os.path.basename(Path(src_file).parents[1])\n",
        "                    full_name = dataset + '-' + subfolder +'-'+ file\n",
        "                    new_path = os.path.join(destination_images, full_name)\n",
        "\n",
        "                    if full_name[:-4] in file_list:\n",
        "                        shutil.copy(src_file, dst_file)\n",
        "                        shutil.move(dst_file, new_path)\n",
        "            elif directory == 'labels':\n",
        "                source_labels_path = os.path.join(root, directory)\n",
        "                for file in os.listdir(source_labels_path):\n",
        "                    src_file = os.path.join(source_labels_path, file)\n",
        "                    dst_file = os.path.join(destination_labels, file)\n",
        "\n",
        "                    subfolder = os.path.basename(Path(src_file).parents[1])\n",
        "                    full_name = dataset + '-' + subfolder +'-'+ file\n",
        "                    new_path = os.path.join(destination_labels, full_name)\n",
        "\n",
        "                    if full_name[:-4] in file_list:\n",
        "                        shutil.copy(src_file, dst_file)\n",
        "                        shutil.move(dst_file, new_path)"
      ],
      "metadata": {
        "id": "0lZi7MRxXsUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_images = '/content/datasets/DELT/images'\n",
        "destination_labels = '/content/datasets/DELT/labels'\n",
        "\n",
        "\n",
        "file_list = full_name_func(source_folder,dataset)\n",
        "drive_to_colab(source_folder,destination_images,destination_labels,dataset,file_list)\n"
      ],
      "metadata": {
        "id": "7yJtO7rpXwEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la estructura de train/val/test\n",
        "if not os.path.exists('DELT'):\n",
        "      for split in ['train','val', 'test']:\n",
        "          os.makedirs(f'datasets/DELT/{split}/images')\n",
        "          os.makedirs(f'datasets/DELT/{split}/labels')"
      ],
      "metadata": {
        "id": "AdGLtENIRV4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliteamos las imagenes y labels\n",
        "def get_filenames(folder):\n",
        "    filenames = set()\n",
        "\n",
        "    for path in glob.glob(os.path.join(folder, '*.*')):\n",
        "\n",
        "        filename = os.path.split(path)[-1]\n",
        "        filenames.add(filename)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "def split_dataset(image_names, train_size, val_size):\n",
        "    for i, image_name in enumerate(image_names):\n",
        "\n",
        "        label_name = image_name.replace('.JPG', '.txt')\n",
        "        label_name = label_name.replace('.jpg', '.txt')\n",
        "\n",
        "        if i < train_size:\n",
        "            split = 'train'\n",
        "        elif i < train_size + val_size:\n",
        "            split = 'val'\n",
        "        else:\n",
        "            split = 'test'\n",
        "\n",
        "        source_image_path = f'datasets/DELT/images/{image_name}'\n",
        "        source_label_path = f'datasets/DELT/labels/{label_name}'\n",
        "\n",
        "        target_image_folder = f'datasets/DELT/{split}/images'\n",
        "        target_label_folder = f'datasets/DELT/{split}/labels'\n",
        "\n",
        "        shutil.copy(source_image_path, target_image_folder)\n",
        "        try:\n",
        "          shutil.copy(source_label_path, target_label_folder) # No todas las imagenes tienen label\n",
        "        except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "turtle_images = get_filenames('datasets/DELT/images')\n",
        "turtle_images = np.array(list(turtle_images))\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(turtle_images)\n",
        "\n",
        "train_size = int(np.floor(len(turtle_images)*0.8))\n",
        "val_size = int(np.floor(len(turtle_images)*0.2))\n",
        "\n",
        "split_dataset(turtle_images, train_size, val_size)"
      ],
      "metadata": {
        "id": "sicv_m1nQCBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metemos en el set de validación los datos antiguos en la misma proporcion\n",
        "\n",
        "file_list = full_name_func(old_dataset_path,dataset,frames = n_frames)\n",
        "\n",
        "turtle_images = np.array(list(file_list))\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(turtle_images)\n",
        "\n",
        "# Movemos imagenes al dataset de validación\n",
        "destination_images = '/content/datasets/DELT/val/images'\n",
        "destination_labels = '/content/datasets/DELT/val/labels'\n",
        "val_images = turtle_images[:val_size]\n",
        "drive_to_colab(old_dataset_path,destination_images,destination_labels,dataset,val_images)\n",
        "\n",
        "# Movemos imagenes al dataset de test\n",
        "destination_images = '/content/datasets/DELT/test/images'\n",
        "destination_labels = '/content/datasets/DELT/test/labels'\n",
        "test_images = turtle_images[val_size:2*val_size]\n",
        "drive_to_colab(old_dataset_path,destination_images,destination_labels,dataset,test_images)"
      ],
      "metadata": {
        "id": "9ACiCz1PZwbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "SDkc6nktb0Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos Comet ML\n",
        "import comet_ml\n",
        "\n",
        "comet_ml.init()"
      ],
      "metadata": {
        "id": "seffMQIvZt0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo\n",
        "model = YOLO(YOLO_model)\n",
        "\n",
        "date_string = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "project_name = dataset+ '-' + date_string\n",
        "\n",
        "results = model.train(data=\"DELTv11.yaml\", epochs=300, freeze=11,patience = 15, project = project_folder, name = project_name)"
      ],
      "metadata": {
        "id": "38O0PiSvZmjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "3Tc-ZAksyUC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testeamos el nuevo modelo contra el dataset de test\n",
        "weigths_path = project_folder + project_name + '/weights/best.pt'\n",
        "\n",
        "# Usamos el .yaml de validacion\n",
        "model = YOLO(weigths_path, data = 'DELTv11_validation.yaml')\n",
        "metrics = model.val()"
      ],
      "metadata": {
        "id": "qTyJkNp52F-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testeamos el antiguo modelo contra el dataset de test\n",
        "weigths_path = project_folder+model_v+'/weights/best.pt'\n",
        "\n",
        "model = YOLO(weigths_path, data = 'DELTv11_validation.yaml')\n",
        "metrics = model.val()"
      ],
      "metadata": {
        "id": "DHEuqj0A2GjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}